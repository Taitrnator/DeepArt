{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-03-21 19:48:40--  https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 2607:f8b0:4004:809::2010, 172.217.13.240\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2607:f8b0:4004:809::2010|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 49937555 (48M) [application/zip]\n",
      "Saving to: ‘../data/inception5h.zip’\n",
      "\n",
      "inception5h.zip     100%[===================>]  47.62M  8.31MB/s    in 5.8s    \n",
      "\n",
      "2018-03-21 19:48:46 (8.25 MB/s) - ‘../data/inception5h.zip’ saved [49937555/49937555]\n",
      "\n",
      "Archive:  ../data/inception5h.zip\n",
      "  inflating: ../data/inception5h/imagenet_comp_graph_label_strings.txt  \n",
      "  inflating: ../data/inception5h/tensorflow_inception_graph.pb  \n",
      "  inflating: ../data/inception5h/LICENSE  \n"
     ]
    }
   ],
   "source": [
    "#this is virtually untouched neural synth. The output of neural synth is interesting, \n",
    "#the problem with it is that it seeks to fill all the space in a canvas\n",
    "#this method builds on earlier work:\n",
    "#apply a GAN generated composition mask on the output of neural synth.\n",
    "#the end result should be a more aesthetically appealing image than vanilla neural synth (or\n",
    "#other methods such as deep dream)\n",
    "\n",
    "!wget -P ../data/ https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip\n",
    "!unzip ../data/inception5h.zip -d ../data/inception5h/\n",
    "!rm ../data/inception5h.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tait/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named 'lapnorm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-db5ece30489e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlapnorm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'lapnorm'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from io import BytesIO\n",
    "import math, time, copy, json, os\n",
    "import glob\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from random import random\n",
    "from io import BytesIO\n",
    "from enum import Enum\n",
    "from functools import partial\n",
    "import PIL.Image\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import tensorflow as tf\n",
    "from lapnorm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-99081aa028bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnum_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'layers' is not defined"
     ]
    }
   ],
   "source": [
    "for l, layer in enumerate(layers):\n",
    "    layer = layer.split(\"/\")[1]\n",
    "    num_channels = T(layer).shape[3]\n",
    "    print(layer, num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_naive(t_obj, img0, iter_n=20, step=1.0):\n",
    "    t_score = tf.reduce_mean(t_obj) # defining the optimization objective\n",
    "    t_grad = tf.gradients(t_score, t_input)[0] # behold the power of automatic differentiation!\n",
    "    img = img0.copy()\n",
    "    for i in range(iter_n):\n",
    "        g, score = sess.run([t_grad, t_score], {t_input:img})\n",
    "        # normalizing the gradient, so the same step size should work \n",
    "        g /= g.std()+1e-8         # for different layers and networks\n",
    "        img += g*step\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img0 = np.random.uniform(size=(200, 200, 3)) + 100.0\n",
    "layer = 'mixed4d_5x5_bottleneck_pre_relu'\n",
    "channel = 20\n",
    "img1 = render_naive(T(layer)[:,:,:,channel], img0, 40, 1.0)\n",
    "display_image(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_multiscale(t_obj, img0, iter_n=10, step=1.0, octave_n=3, octave_scale=1.4):\n",
    "    t_score = tf.reduce_mean(t_obj) # defining the optimization objective\n",
    "    t_grad = tf.gradients(t_score, t_input)[0] # behold the power of automatic differentiation!\n",
    "    img = img0.copy()\n",
    "    for octave in range(octave_n):\n",
    "        if octave>0:\n",
    "            hw = np.float32(img.shape[:2])*octave_scale\n",
    "            img = resize(img, np.int32(hw))\n",
    "        for i in range(iter_n):\n",
    "            g = calc_grad_tiled(img, t_grad)\n",
    "            # normalizing the gradient, so the same step size should work \n",
    "            g /= g.std()+1e-8        # for different layers and networks\n",
    "            img += g*step\n",
    "        print(\"octave %d/%d\"%(octave+1, octave_n))\n",
    "    clear_output()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = 200, 200\n",
    "octave_n = 3\n",
    "octave_scale = 1.4\n",
    "iter_n = 30\n",
    "\n",
    "img0 = np.random.uniform(size=(h, w, 3)) + 100.0\n",
    "\n",
    "layer = 'mixed4d_5x5_bottleneck_pre_relu'\n",
    "channel = 25\n",
    "\n",
    "img1 = render_multiscale(T(layer)[:,:,:,channel], img0, iter_n, 1.0, octave_n, octave_scale)\n",
    "display_image(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_lapnorm(t_obj, img0, iter_n=10, step=1.0, oct_n=3, oct_s=1.4, lap_n=4):\n",
    "    t_score = tf.reduce_mean(t_obj) # defining the optimization objective\n",
    "    t_grad = tf.gradients(t_score, t_input)[0] # behold the power of automatic differentiation!\n",
    "    # build the laplacian normalization graph\n",
    "    lap_norm_func = tffunc(np.float32)(partial(lap_normalize, scale_n=lap_n))\n",
    "    img = img0.copy()\n",
    "    for octave in range(oct_n):\n",
    "        if octave>0:\n",
    "            hw = np.float32(img.shape[:2])*oct_s\n",
    "            img = resize(img, np.int32(hw))\n",
    "        for i in range(iter_n):\n",
    "            g = calc_grad_tiled(img, t_grad)\n",
    "            g = lap_norm_func(g)\n",
    "            img += g*step\n",
    "            print('.', end='')\n",
    "        print(\"octave %d/%d\"%(octave+1, oct_n))\n",
    "    clear_output()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = 300, 400\n",
    "octave_n = 3\n",
    "octave_scale = 1.4\n",
    "iter_n = 10\n",
    "\n",
    "img0 = np.random.uniform(size=(h, w, 3)) + 100.0\n",
    "\n",
    "layer = 'mixed5a_5x5_bottleneck_pre_relu'\n",
    "channel = 25\n",
    "\n",
    "img1 = render_lapnorm(T(layer)[:,:,:,channel], img0, iter_n, 1.0, octave_n, octave_scale)\n",
    "display_image(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lapnorm_multi(t_obj, img0, mask, iter_n=10, step=1.0, oct_n=3, oct_s=1.4, lap_n=4, clear=True):\n",
    "    mask_sizes = get_mask_sizes(mask.shape[0:2], oct_n, oct_s)\n",
    "    img0 = resize(img0, np.int32(mask_sizes[0])) \n",
    "    t_score = [tf.reduce_mean(t) for t in t_obj] # defining the optimization objective\n",
    "    t_grad = [tf.gradients(t, t_input)[0] for t in t_score] # behold the power of automatic differentiation!\n",
    "    # build the laplacian normalization graph\n",
    "    lap_norm_func = tffunc(np.float32)(partial(lap_normalize, scale_n=lap_n))\n",
    "    img = img0.copy()\n",
    "    for octave in range(oct_n):\n",
    "        if octave>0:\n",
    "            hw = mask_sizes[octave] #np.float32(img.shape[:2])*oct_s\n",
    "            img = resize(img, np.int32(hw))\n",
    "        oct_mask = resize(mask, np.int32(mask_sizes[octave]))\n",
    "        for i in range(iter_n):\n",
    "            g_tiled = [lap_norm_func(calc_grad_tiled(img, t)) for t in t_grad]\n",
    "            for g, gt in enumerate(g_tiled):\n",
    "                img += gt * step * oct_mask[:,:,g].reshape((oct_mask.shape[0],oct_mask.shape[1],1))\n",
    "            print('.', end='')\n",
    "        print(\"octave %d/%d\"%(octave+1, oct_n))\n",
    "    if clear:\n",
    "        clear_output()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = 300, 400\n",
    "octave_n = 3\n",
    "octave_scale = 1.4\n",
    "iter_n = 10\n",
    "\n",
    "img0 = np.random.uniform(size=(h, w, 3)) + 100.0\n",
    "\n",
    "objectives = [T('mixed3a_3x3_bottleneck_pre_relu')[:,:,:,25], \n",
    "              T('mixed4d_5x5_bottleneck_pre_relu')[:,:,:,15]]\n",
    "\n",
    "# mask\n",
    "mask = np.zeros((h, w, 2))\n",
    "mask[:150,:,0] = 1.0\n",
    "mask[150:,:,1] = 1.0\n",
    "\n",
    "img1 = lapnorm_multi(objectives, img0, mask, iter_n, 1.0, octave_n, octave_scale)\n",
    "display_image(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = 256, 1024\n",
    "\n",
    "img0 = np.random.uniform(size=(h, w, 3)) + 100.0\n",
    "\n",
    "octave_n = 3\n",
    "octave_scale = 1.4\n",
    "objectives = [T('mixed3b_5x5_bottleneck_pre_relu')[:,:,:,9], \n",
    "              T('mixed4d_5x5_bottleneck_pre_relu')[:,:,:,17]]\n",
    "\n",
    "mask = np.zeros((h, w, 2))\n",
    "mask[:,:,0] = np.linspace(0,1,w)\n",
    "mask[:,:,1] = np.linspace(1,0,w)\n",
    "\n",
    "img1 = lapnorm_multi(objectives, img0, mask, iter_n=20, step=1.0, oct_n=3, oct_s=1.4, lap_n=4)\n",
    "\n",
    "print(\"image\")\n",
    "display_image(img1)\n",
    "print(\"mask\")\n",
    "display_image(255*mask[:,:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = 200, 200\n",
    "\n",
    "# start with random noise\n",
    "img = np.random.uniform(size=(h, w, 3)) + 100.0\n",
    "\n",
    "octave_n = 3\n",
    "octave_scale = 1.4\n",
    "objectives = [T('mixed5a_5x5_bottleneck_pre_relu')[:,:,:,11]]\n",
    "mask = np.ones((h, w, 1))\n",
    "\n",
    "# repeat the generation loop 20 times. notice the feedback -- we make img and then use it the initial input \n",
    "for f in range(20):\n",
    "    mask[:f*10,f*10:] = np.linspace(2, 1, 1)\n",
    "    mask[f*10:,:f*10] = np.linspace(2, 1, 1)\n",
    "    img = lapnorm_multi(objectives, img, mask, iter_n=20, step=1.0, oct_n=3, oct_s=1.4, lap_n=4, clear=False)\n",
    "    display_image(img)    # let's see it\n",
    "    img = resize(img[10:-10,10:-10,:], (h, w))  # before looping back, crop the border by 10 pixels, resize, repeat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
